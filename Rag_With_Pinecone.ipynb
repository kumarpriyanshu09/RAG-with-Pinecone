{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "f76bcd91"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pinecone (vector db, latest official package)\n",
        "!pip install --upgrade pinecone"
      ],
      "metadata": {
        "collapsed": true,
        "id": "cTDu67Ivp7Fw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade \"langchain>=0.2.0\" langchain-openai langchain-pinecone\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "PDk0by13r91G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade langchain-experimental\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "zk5KsE9xsBcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/openai/whisper.git\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "gs6kbIvMsDa2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade yt-dlp\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "PxOnKcEbrZnR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tqdm pydub\n"
      ],
      "metadata": {
        "id": "VKMWb7hRsHWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade numpy\n"
      ],
      "metadata": {
        "id": "1h3j6u44sI_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
        "os.environ[\"PINECONE_API_KEY\"] = userdata.get(\"PINECONE_API_KEY\")\n",
        "os.environ[\"PINECONE_ENVIRONMENT\"] = \"us-east1-aws\""
      ],
      "metadata": {
        "id": "ZFdzFShDSfc8"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import yt_dlp\n",
        "import whisper\n",
        "import os\n",
        "from urllib.parse import urlparse, parse_qs\n",
        "\n",
        "def get_youtube_video_id(url):\n",
        "    # Handles standard YouTube URLs\n",
        "    query = urlparse(url)\n",
        "    if query.hostname in ['www.youtube.com', 'youtube.com']:\n",
        "        return parse_qs(query.query)['v'][0]\n",
        "    elif query.hostname == 'youtu.be':\n",
        "        return query.path[1:]\n",
        "    else:\n",
        "        raise ValueError(\"Invalid YouTube URL\")\n",
        "\n",
        "def download_and_transcribe_youtube(youtube_url, output_dir=\"/content/drive/MyDrive/github/youtube-rag/rag\"):\n",
        "    video_id = get_youtube_video_id(youtube_url)\n",
        "    output_filename = os.path.join(output_dir, f'audio_{video_id}.%(ext)s')\n",
        "    ydl_opts = {\n",
        "        'format': 'bestaudio/best',\n",
        "        'outtmpl': output_filename,\n",
        "        'postprocessors': [{\n",
        "            'key': 'FFmpegExtractAudio',\n",
        "            'preferredcodec': 'mp3',\n",
        "            'preferredquality': '192',\n",
        "        }],\n",
        "        'keepvideo': False,\n",
        "    }\n",
        "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "        ydl.download([youtube_url])\n",
        "    audio_path = os.path.join(output_dir, f\"audio_{video_id}.mp3\")\n",
        "\n",
        "    model = whisper.load_model(\"base\")\n",
        "    result = model.transcribe(audio_path)\n",
        "    transcript = result['text']\n",
        "\n",
        "    transcript_path = os.path.join(output_dir, f\"transcript_{video_id}.txt\")\n",
        "    with open(transcript_path, \"w\") as f:\n",
        "        f.write(transcript)\n",
        "    return transcript, transcript_path\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "6_NMvpxHSf-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "youtube_url = \"https://www.youtube.com/watch?v=HgcoFVqG0ms\"\n",
        "transcript, transcript_path = download_and_transcribe_youtube(youtube_url)\n",
        "print(f\"Transcript saved at: {transcript_path}\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "s38pr1N4UlhK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_experimental.text_splitter import SemanticChunker\n",
        "from langchain_openai.embeddings import OpenAIEmbeddings\n"
      ],
      "metadata": {
        "id": "N85BeXl-UuVh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/github/youtube-rag/rag/transcript_HgcoFVqG0ms.txt\") as f:\n",
        "    text = f.read()\n"
      ],
      "metadata": {
        "id": "Hv3yLfbnazAf"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = SemanticChunker(\n",
        "    OpenAIEmbeddings(),                  # uses your OpenAI key automatically\n",
        "    breakpoint_threshold_type=\"percentile\",    # can also be 'standard_deviation', 'interquartile', or 'gradient'\n",
        "    breakpoint_threshold_amount=95.0           # default is 95, tune this percentile if you want more/fewer splits\n",
        ")\n"
      ],
      "metadata": {
        "id": "2lz2XFJGazu-"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = text_splitter.create_documents([text])\n",
        "print(f\"Total semantic chunks: {len(docs)}\")\n",
        "for i, d in enumerate(docs):\n",
        "    print(f\"\\n--- Chunk {i+1} ---\\n{d.page_content[:300]}\")  # Show first 300 chars for preview\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "XVFyEUEua4Lh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "\n",
        "index_name = \"youtube-rag-index\"\n",
        "\n",
        "pc = Pinecone(api_key=os.environ[\"PINECONE_API_KEY\"])\n",
        "if index_name not in pc.list_indexes().names():\n",
        "    pc.create_index(\n",
        "        name=index_name,\n",
        "        dimension=1536,        # 1536 for OpenAI Embeddings\n",
        "        metric='cosine',       # Or 'euclidean', but cosine is default for OpenAI\n",
        "        spec=ServerlessSpec(cloud='aws', region='us-east-1')\n",
        "    )\n"
      ],
      "metadata": {
        "id": "vFvBy0-UbB6F"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_pinecone import Pinecone as LangChainPinecone\n",
        "from langchain_openai.embeddings import OpenAIEmbeddings\n",
        "embeddings = OpenAIEmbeddings()\n",
        "vectorstore = LangChainPinecone.from_documents(\n",
        "    docs,\n",
        "    embeddings,\n",
        "    index_name=index_name\n",
        ")\n",
        "print(\"Semantic chunks embedded and uploaded to Pinecone vector index!\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "S0XKT3DPb2Ll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vectorstore.as_retriever()\n"
      ],
      "metadata": {
        "id": "Wn1BHAaEcsxK"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(\n",
        "    openai_api_key=os.environ[\"OPENAI_API_KEY\"],\n",
        "    model_name=\"gpt-4.1\"  # or \"gpt-4o\" etc.\n",
        ")\n"
      ],
      "metadata": {
        "id": "fIITLcr4kef1"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.schema.output_parser import StrOutputParser\n",
        "from langchain.schema.runnable import RunnableMap, RunnablePassthrough\n",
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "# Define prompt for the LLM.\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\",\n",
        "     \"\"\"You are an expert assistant. Using ONLY the provided context, answer the user's question.\n",
        "     ALWAYS respond in this JSON format:\n",
        "     {{\n",
        "       \"answer\": (string, best answer to the question from context),\n",
        "       \"citations\": (array of strings, exact text of the context/chunks used)\n",
        "     }}\n",
        "\n",
        "     Context:\n",
        "     {context}\"\"\"),\n",
        "    (\"human\", \"{question}\")\n",
        "])\n",
        "\n",
        "\n",
        "# Build the chain\n",
        "rag_chain = (\n",
        "    RunnableMap({\n",
        "        \"context\": retriever,\n",
        "        \"question\": RunnablePassthrough()\n",
        "    })  # This builds {\"context\": retriever(query), \"question\": query}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | JsonOutputParser()  # Get just the text out if you want\n",
        ")\n"
      ],
      "metadata": {
        "id": "jbZiAwM0khDv"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is a LangGraph or an agent according to the video?\"\n",
        "answer = rag_chain.invoke(query)\n",
        "print(\"Answer:\", answer)\n"
      ],
      "metadata": {
        "id": "MxAUCgGskkrs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fBpDsGb7kp0g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}